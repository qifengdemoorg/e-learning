name: Frontend CI/CD - Azure AKS

on:
  pull_request:
    # branches: [main, develop]
    paths:
      - 'frontend/**'
      - '.github/workflows/frontend-deploy.yml'
      - 'deployment/aks/frontend/**'
  push:
    branches: [main]
    paths:
      - 'frontend/**'
      - '.github/workflows/frontend-deploy.yml'
      - 'deployment/aks/frontend/**'

env:
  AZURE_CONTAINER_REGISTRY: democrhk
  CONTAINER_NAME: elearning-frontend
  RESOURCE_GROUP: DemoAKS-RG-HK
  CLUSTER_NAME: demoaks-hk
  DEPLOYMENT_MANIFEST_PATH: 'deployment/aks/frontend'
  ACR_LOGIN_SERVER: democrhk.azurecr.io

jobs:
  build:
    runs-on: ubuntu-latest
    
    outputs:
      image-tag: ${{ steps.meta.outputs.tags }}
      image-digest: ${{ steps.build.outputs.digest }}
      should-push: ${{ steps.should_push.outputs.should_push }}
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '22'
        cache: 'npm'
        cache-dependency-path: 'frontend/package-lock.json'

    - name: Install dependencies
      working-directory: ./frontend
      run: npm ci

    - name: Run type checking
      working-directory: ./frontend
      run: npm run type-check

    - name: Build application
      working-directory: ./frontend
      run: npm run build

    # Only build and push Docker image on main branch or when secrets are available
    - name: Check if push is needed
      id: should_push
      run: |
        if [[ "${{ github.ref }}" == "refs/heads/main" ]]; then
          echo "should_push=true" >> $GITHUB_OUTPUT
        else
          echo "should_push=false" >> $GITHUB_OUTPUT
        fi

    # Azure Container Registry login (only when pushing)
    - name: Azure Container Registry login
      if: steps.should_push.outputs.should_push == 'true'
      uses: azure/docker-login@v1
      with:
        login-server: ${{ env.ACR_LOGIN_SERVER }}
        username: ${{ secrets.ACR_USERNAME || 'dummy-user' }}
        password: ${{ secrets.ACR_PASSWORD || 'dummy-password' }}

    # Extract metadata for Docker image
    - name: Extract metadata
      id: meta
      uses: docker/metadata-action@v5
      with:
        images: ${{ env.ACR_LOGIN_SERVER }}/${{ env.CONTAINER_NAME }}
        tags: |
          type=ref,event=branch
          type=ref,event=pr,prefix=pr-
          type=raw,value=latest,enable={{is_default_branch}}

    # Build and push Docker image (only on main branch)
    - name: Build and push Docker image
      id: build
      if: steps.should_push.outputs.should_push == 'true'
      uses: docker/build-push-action@v5
      with:
        context: ./frontend
        file: ./frontend/Dockerfile
        push: true
        tags: ${{ steps.meta.outputs.tags }}
        labels: ${{ steps.meta.outputs.labels }}
        build-args: |
          VITE_API_BASE_URL=https://localhost:8000/api
          VITE_APP_TITLE=Contoso E-Learning Platform

    # Build only for PR (no push)
    - name: Build Docker image (PR only)
      if: steps.should_push.outputs.should_push == 'false'
      uses: docker/build-push-action@v5
      with:
        context: ./frontend
        file: ./frontend/Dockerfile
        push: false
        load: true
        tags: ${{ steps.meta.outputs.tags }}
        labels: ${{ steps.meta.outputs.labels }}
        build-args: |
          VITE_API_BASE_URL=http://localhost:8000/api
          VITE_APP_TITLE=Contoso E-Learning Platform

  security-scan:
    runs-on: ubuntu-latest
    needs: build
    if: github.event_name == 'pull_request'
    
    permissions:
      security-events: write
      actions: read
      contents: read
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3

    - name: Build Docker image for scanning
      uses: docker/build-push-action@v5
      with:
        context: ./frontend
        file: ./frontend/Dockerfile
        push: false
        load: true
        tags: ${{ env.CONTAINER_NAME }}:scan
        build-args: |
          VITE_API_BASE_URL=http://localhost:8000/api
          VITE_APP_TITLE=Contoso E-Learning Platform

    # Run Trivy vulnerability scanner in repo mode
    - name: Run Trivy vulnerability scanner (repo)
      uses: aquasecurity/trivy-action@master
      with:
        scan-type: 'fs'
        scan-ref: './frontend'
        format: 'sarif'
        output: 'trivy-repo-results.sarif'
        severity: 'CRITICAL,HIGH,MEDIUM'

    # Run Trivy vulnerability scanner on Docker image
    - name: Run Trivy vulnerability scanner (image)
      uses: aquasecurity/trivy-action@master
      with:
        image-ref: '${{ env.CONTAINER_NAME }}:scan'
        format: 'sarif'
        output: 'trivy-image-results.sarif'
        severity: 'CRITICAL,HIGH,MEDIUM'

    # Run Trivy configuration scanner
    - name: Run Trivy configuration scanner
      uses: aquasecurity/trivy-action@master
      with:
        scan-type: 'config'
        scan-ref: './frontend'
        format: 'sarif'
        output: 'trivy-config-results.sarif'
        severity: 'CRITICAL,HIGH,MEDIUM'

    # Upload Trivy scan results to GitHub Security tab
    - name: Upload Trivy scan results to GitHub Security tab
      uses: github/codeql-action/upload-sarif@v2
      if: always()
      with:
        sarif_file: |
          trivy-repo-results.sarif
          trivy-image-results.sarif
          trivy-config-results.sarif

    # Generate human-readable report
    - name: Run Trivy vulnerability scanner (human readable)
      uses: aquasecurity/trivy-action@master
      with:
        image-ref: '${{ env.CONTAINER_NAME }}:scan'
        format: 'table'
        output: 'trivy-results.txt'
        severity: 'CRITICAL,HIGH,MEDIUM'

    # Post scan results as PR comment
    - name: Comment PR with scan results
      uses: actions/github-script@v6
      if: always()
      with:
        script: |
          const fs = require('fs');
          const path = './trivy-results.txt';
          
          if (fs.existsSync(path)) {
            const scanResults = fs.readFileSync(path, 'utf8');
            const truncatedResults = scanResults.length > 60000 ? 
              scanResults.substring(0, 60000) + '\n\n... (truncated)' : 
              scanResults;
            
            // Create or update PR comment
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });
            
            const existingComment = comments.find(comment => 
              comment.body.includes('ðŸ”’ Security Scan Results')
            );
            
            const commentBody = `## ðŸ”’ Security Scan Results

            **Image**: \`${{ env.CONTAINER_NAME }}:scan\`
            **Scan Time**: ${new Date().toISOString()}
            **Workflow**: ${{ github.workflow }}
            **Run ID**: ${{ github.run_id }}

            ### Vulnerability Scan Results

            <details>
            <summary>Click to expand scan results</summary>

            \`\`\`
            ${truncatedResults}
            \`\`\`

            </details>

            ### Security Reports
            - ðŸ“Š **Repository Scan**: Check [Security tab](../../security/code-scanning) for detailed findings
            - ðŸ³ **Image Scan**: Docker image vulnerability assessment
            - âš™ï¸ **Configuration Scan**: Infrastructure and config security check

            > **Note**: This scan was performed on PR #${{ github.event.number }}. Critical and high severity issues should be addressed before merging.

            *Powered by [Trivy Security Scanner](https://github.com/aquasecurity/trivy)*`;
            
            if (existingComment) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: existingComment.id,
                body: commentBody
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: commentBody
              });
            }
          } else {
            console.log('Trivy results file not found');
          }

    # Create a status check for branch protection
    - name: Create security scan status
      uses: actions/github-script@v6
      if: always()
      with:
        script: |
          const fs = require('fs');
          const path = './trivy-results.txt';
          
          let state = 'success';
          let description = 'Security scan completed successfully';
          
          if (fs.existsSync(path)) {
            const scanResults = fs.readFileSync(path, 'utf8');
            const criticalCount = (scanResults.match(/CRITICAL/g) || []).length;
            const highCount = (scanResults.match(/HIGH/g) || []).length;
            
            if (criticalCount > 0) {
              state = 'failure';
              description = `Security scan failed: ${criticalCount} critical vulnerabilities found`;
            } else if (highCount > 5) {
              state = 'success';  // Don't fail for high vulnerabilities, but note them
              description = `Security scan passed with warnings: ${highCount} high-severity vulnerabilities`;
            } else {
              description = `Security scan passed: No critical vulnerabilities found`;
            }
          } else {
            state = 'failure';
            description = 'Security scan failed: Results file not found';
          }
          
          await github.rest.repos.createCommitStatus({
            owner: context.repo.owner,
            repo: context.repo.repo,
            sha: context.payload.pull_request.head.sha,
            state: state,
            target_url: `${context.payload.repository.html_url}/actions/runs/${context.runId}`,
            description: description,
            context: 'security/trivy-scan'
          });

    # Fail the job if critical vulnerabilities are found
    - name: Check for critical vulnerabilities
      run: |
        if [ -f trivy-results.txt ]; then
          echo "Checking for critical vulnerabilities..."
          
          # Count critical vulnerabilities
          CRITICAL_COUNT=$(grep -c "CRITICAL" trivy-results.txt || echo "0")
          HIGH_COUNT=$(grep -c "HIGH" trivy-results.txt || echo "0")
          
          echo "Critical vulnerabilities found: $CRITICAL_COUNT"
          echo "High vulnerabilities found: $HIGH_COUNT"
          
          # Set output for other steps
          echo "critical_count=$CRITICAL_COUNT" >> $GITHUB_OUTPUT
          echo "high_count=$HIGH_COUNT" >> $GITHUB_OUTPUT
          
          # Warning for high vulnerabilities, fail for critical
          if [ "$CRITICAL_COUNT" -gt "0" ]; then
            echo "âŒ CRITICAL vulnerabilities found! Please address these issues before merging."
            echo "::error title=Critical Vulnerabilities::Found $CRITICAL_COUNT critical vulnerabilities in the Docker image"
            exit 1
          elif [ "$HIGH_COUNT" -gt "5" ]; then
            echo "âš ï¸ Warning: $HIGH_COUNT high-severity vulnerabilities found"
            echo "::warning title=High Vulnerabilities::Found $HIGH_COUNT high-severity vulnerabilities"
          else
            echo "âœ… No critical vulnerabilities found"
          fi
        else
          echo "âš ï¸ Warning: Trivy results file not found"
        fi

  # Quick security scan for main branch pushes
  security-scan-main:
    runs-on: ubuntu-latest
    needs: build
    if: github.ref == 'refs/heads/main'
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    # Run a quick Trivy scan on the pushed image
    - name: Run Trivy vulnerability scanner (quick scan)
      uses: aquasecurity/trivy-action@master
      with:
        image-ref: '${{ needs.build.outputs.image-tag }}'
        format: 'table'
        severity: 'CRITICAL,HIGH'
        exit-code: '0'  # Don't fail the pipeline for main branch

  deploy:
    needs: [build]
    runs-on: ubuntu-latest
    environment: production
    if: github.ref == 'refs/heads/main'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Azure Login
      uses: azure/login@v1
      with:
        creds: ${{ secrets.AZURE_CREDENTIALS }}
    
    - name: Set up kubectl
      uses: azure/setup-kubectl@v3
      with:
        version: 'latest'
    
    - name: Get AKS credentials
      run: |
        az aks get-credentials --resource-group ${{ env.RESOURCE_GROUP }} --name ${{ env.CLUSTER_NAME }}
    
    - name: Create namespace if not exists
      run: |
        kubectl apply -f deployment/aks/frontend/01-namespace.yaml
    
    - name: Apply ConfigMaps and Secrets
      run: |
        kubectl apply -f deployment/aks/frontend/02-configmap.yaml
    
    - name: Extract image tag from build output
      id: image_info
      run: |
        # ä»Žæž„å»ºè¾“å‡ºä¸­æå–é•œåƒæ ‡ç­¾
        FULL_IMAGE_TAGS="${{ needs.build.outputs.image-tag }}"
        echo "Full image tags from build: $FULL_IMAGE_TAGS"
        
        # metadata-action è¿”å›žçš„æ˜¯å¤šè¡Œæ ‡ç­¾ï¼Œæˆ‘ä»¬éœ€è¦èŽ·å–å®Œæ•´çš„é•œåƒåç§°:æ ‡ç­¾
        # é€šå¸¸ç¬¬ä¸€è¡Œæ˜¯ä¸»è¦æ ‡ç­¾
        MAIN_IMAGE_TAG=$(echo "$FULL_IMAGE_TAGS" | head -n1)
        echo "Using main image tag: $MAIN_IMAGE_TAG"
        
        # ä»Žå®Œæ•´é•œåƒåç§°ä¸­æå–æ ‡ç­¾éƒ¨åˆ†
        TAG_ONLY=$(echo "$MAIN_IMAGE_TAG" | cut -d':' -f2)
        echo "Tag only: $TAG_ONLY"
        
        echo "full_image=$MAIN_IMAGE_TAG" >> $GITHUB_OUTPUT
        echo "tag_only=$TAG_ONLY" >> $GITHUB_OUTPUT
    
    - name: Update deployment image
      run: |
        # Create a backup of the original file
        cp deployment/aks/frontend/03-deployment.yaml deployment/aks/frontend/03-deployment.yaml.backup
        
        # Update deployment manifest with the actual built image tag
        # Use single quotes and escape properly to avoid YAML issues
        sed -i 's|#{ACR_LOGIN_SERVER}#|${{ env.ACR_LOGIN_SERVER }}|g' deployment/aks/frontend/03-deployment.yaml
        sed -i 's|#{IMAGE_TAG}#|${{ steps.image_info.outputs.tag_only }}|g' deployment/aks/frontend/03-deployment.yaml
        
        # For URL replacement, ensure proper quoting
        API_BASE_URL="https://api.elearning.demo.com"
        sed -i "s|#{VITE_API_BASE_URL}#|${API_BASE_URL}|g" deployment/aks/frontend/03-deployment.yaml
        
        echo "=== Updated deployment manifest ==="
        cat deployment/aks/frontend/03-deployment.yaml | grep -A 10 -B 5 "image:"
        
        echo "=== Environment variables section ==="
        cat deployment/aks/frontend/03-deployment.yaml | grep -A 10 -B 2 "VITE_API_BASE_URL"
        
        echo "=== Validating YAML syntax ==="
        kubectl apply --dry-run=client -f deployment/aks/frontend/03-deployment.yaml
        
        echo "Using full image: ${{ steps.image_info.outputs.full_image }}"
        echo "Using tag: ${{ steps.image_info.outputs.tag_only }}"
    
    - name: Deploy application
      run: |
        # Apply all manifests in order
        echo "Applying deployment manifest..."
        kubectl apply -f deployment/aks/frontend/03-deployment.yaml
        
        echo "Applying service manifest..."
        kubectl apply -f deployment/aks/frontend/04-service.yaml
        
        echo "Applying ingress manifest..."
        kubectl apply -f deployment/aks/frontend/05-ingress.yaml
        
        echo "Applying HPA manifest..."
        kubectl apply -f deployment/aks/frontend/06-hpa.yaml
        
        echo "Checking deployment status..."
        kubectl get deployments -n elearning
       # kubectl apply -f deployment/aks/frontend/07-network-policy.yaml
    
    - name: Wait for deployment rollout
      run: |
        kubectl rollout status deployment/elearning-frontend -n elearning --timeout=600s
    
    - name: Verify deployment health
      run: |
        echo "Checking pod status..."
        kubectl get pods -n elearning -l app=elearning-frontend
        
        echo "Checking service status..."
        kubectl get svc -n elearning -l app=elearning-frontend
        
        echo "Checking ingress status..."
        kubectl get ingress -n elearning
        
        echo "Checking HPA status..."
        kubectl get hpa -n elearning
        
        # Wait for pods to be ready
        kubectl wait --for=condition=ready pod -l app=elearning-frontend -n elearning --timeout=300s
